{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model arhitecture and training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE31ZuGK3B-1"
      },
      "source": [
        "## MODEL ARCHITECTURE FOR LIDAR AND CAMERA DATA\n",
        "-----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nAOfXYW3H6P"
      },
      "source": [
        "### Overview\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTtJ54Db22wf"
      },
      "source": [
        "# General import ->\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_o5wIjH3TlV"
      },
      "source": [
        "# Model related import ->\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_bDq8mjBM_F"
      },
      "source": [
        "# File import ->\n",
        "import steering_angles\n",
        "import model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL7O7bAP35Bk"
      },
      "source": [
        "def get_model():\n",
        "    # Bottom layers for reference ->\n",
        "    pretrained_model = VGG16(weights='imagenet', include_top=False, input_shape=[48, 75, 3])\n",
        "    x = pretrained_model.output\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Add top layers ->\n",
        "    x = Dense(3000, activation='relu', name='fc1', W_regularizer=l2(0.0001))(x)\n",
        "    x = Dense(1000, activation='relu', name='fc2', W_regularizer=l2(0.0001))(x)\n",
        "    x = Dense(500, activation='relu', name='fc2', W_regularizer=l2(0.0001))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    predictions = Dense(1)(x)\n",
        "\n",
        "    model = Model(input=pretrained_model.input, output=predictions)\n",
        "    \n",
        "    # Train top layers only ->\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  \n",
        "    # Get the training and validation data from pickle ->\n",
        "\n",
        "    training_pickle = 'train.p'\n",
        "    with open(training_data, 'rb') as handle:\n",
        "        training_info = pickle.load(handle)\n",
        "\n",
        "    validation_pickle = 'validation.p'\n",
        "    with open(validation_pickle, 'rb') as handle:\n",
        "        validation_info = pickle.load(handle)\n",
        "\n",
        "    # Create model ->\n",
        "\n",
        "    model = create_model()\n",
        "    checkpoint = ModelCheckpoint(filepath='model-{epoch:02d}.h5')\n",
        "    callback_list = [checkpoint]\n",
        "    \n",
        "    # Train the model ->\n",
        "    model.fit_generator(\n",
        "        get_steering_angle(training_info, batch_size=48),\n",
        "        samples_per_epoch=1000, nb_epoch=30,\n",
        "        validation=validation(validation_info), validation_nr=len(validation_info),\n",
        "        callbacks=callback_list)\n",
        "\n",
        "    # Save the model ->\n",
        "    model.save('model.h5')\n",
        "    print(\"The model is saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ctxh23JpRj"
      },
      "source": [
        "Beforre training the model you should read this -> https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c (step-by-step tutorial for training with the model...) and from this https://www.researchgate.net/post/How-to-choose-from-which-layer-to-start-unfreezing-pretrained-model (explains a bit how to start changing, i.e training, the model if using freezed weights...) + https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751 "
      ]
    }
  ]
}